{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "path = 'field_of_study_exercise.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level</th>\n",
       "      <th>level_name</th>\n",
       "      <th>field_of_study</th>\n",
       "      <th>academic_field</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-, Marketing/Marketing Management, General</td>\n",
       "      <td>marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>“Wellness Counseling Certificate”</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(BA) Hons Fashion, Fashion/Apparel Design</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(BA) Liberal Arts, Liberal Arts and Sciences/L...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>* Career certificate of Marketing.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1st Class Honour, Information System and Compu...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2:1, Business Management</td>\n",
       "      <td>business management</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2:1, French and Hispanic Studies</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.1, Graphic Design and Illustration</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.1, Management</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  level level_name                                     field_of_study  \\\n",
       "0   NaN        NaN         -, Marketing/Marketing Management, General   \n",
       "1   NaN        NaN                  “Wellness Counseling Certificate”   \n",
       "2   NaN        NaN          (BA) Hons Fashion, Fashion/Apparel Design   \n",
       "3   NaN        NaN  (BA) Liberal Arts, Liberal Arts and Sciences/L...   \n",
       "4   NaN        NaN                 * Career certificate of Marketing.   \n",
       "5   NaN        NaN  1st Class Honour, Information System and Compu...   \n",
       "6   NaN        NaN                           2:1, Business Management   \n",
       "7   NaN        NaN                   2:1, French and Hispanic Studies   \n",
       "8   NaN        NaN               2.1, Graphic Design and Illustration   \n",
       "9   NaN        NaN                                    2.1, Management   \n",
       "\n",
       "        academic_field  \n",
       "0            marketing  \n",
       "1                  NaN  \n",
       "2                  NaN  \n",
       "3                  NaN  \n",
       "4                  NaN  \n",
       "5                  NaN  \n",
       "6  business management  \n",
       "7                  NaN  \n",
       "8                  NaN  \n",
       "9                  NaN  "
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(path)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove duplicate rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 375 entries, 0 to 374\n",
      "Data columns (total 4 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   level           322 non-null    object\n",
      " 1   level_name      312 non-null    object\n",
      " 2   field_of_study  375 non-null    object\n",
      " 3   academic_field  141 non-null    object\n",
      "dtypes: object(4)\n",
      "memory usage: 11.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data = data.drop_duplicates()\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate Missing Values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 375 entries, 0 to 374\n",
      "Data columns (total 4 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   level           322 non-null    object\n",
      " 1   level_name      312 non-null    object\n",
      " 2   field_of_study  375 non-null    object\n",
      " 3   academic_field  141 non-null    object\n",
      "dtypes: object(4)\n",
      "memory usage: 11.8+ KB\n",
      " -- null count:\n",
      "level              53\n",
      "level_name         63\n",
      "field_of_study      0\n",
      "academic_field    234\n",
      "dtype: int64\n",
      " -- null ratios:\n",
      "level             0.141333\n",
      "level_name        0.168000\n",
      "field_of_study    0.000000\n",
      "academic_field    0.624000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "data.info()\n",
    "null_counts = data.isnull()\n",
    "print(\" -- null count:\\n{}\".format(null_counts.sum()))\n",
    "print(\" -- null ratios:\\n{}\".format(null_counts.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When dealing with machine learning and a dataset that is both small and incomplete, filling in missing values (handling NA columns) is a necessary step to maximize the utility of the available data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column Cleanup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['level', 'level_name', 'field_of_study', 'academic_field'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Clean column names\n",
    "cleaned_data = data \n",
    "cleaned_data.columns = cleaned_data.columns.str.strip()\n",
    "# Display cleaned column names\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Type Conversion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in cleaned_data.columns:\n",
    "    cleaned_data[column]=cleaned_data[column].astype('str')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove or Replace Unwanted Characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Special characters:\n",
      "['\"', '#', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', ']', '’', '“', '”']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "# Define a regular expression to remove special characters\n",
    "pattern = r'[^\\w\\s]'  # Matches characters that are not alphanumeric or whitespace\n",
    "# Create an empty dictionary to store column-wise special characters\n",
    "special_chars = set()\n",
    "# Iterate through each column in the DataFrame\n",
    "for col in cleaned_data.columns:\n",
    "    # Create an empty set for the current column's special characters\n",
    "    \n",
    "\n",
    "    # Iterate through each element in the column\n",
    "    for element in data[col].values:\n",
    "        # Find all special characters using the regular expression\n",
    "        matches = re.findall(pattern, str(element))\n",
    "        # Add unique characters to the set\n",
    "        special_chars.update(matches)\n",
    "\n",
    "# Print the dictionary showing special characters by column\n",
    "print(\"Special characters:\")\n",
    "print(f\"{sorted(special_chars)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mapping_specific_pattern ={\n",
    "    'bba':'',\n",
    "    'honours': 'Hons',\n",
    "    'bachelor degree in':'',\n",
    "    'bachelor degree':'',\n",
    "    'bachelor in':'',\n",
    "    'bachelor of':'',\n",
    "    'basc': '',\n",
    "    '&': 'and',\n",
    "    'bachelor hons in': ''\n",
    "}\n",
    "# Function to replace substrings regardless of case sensitivity\n",
    "def replace_substrings(string, replacements):\n",
    "    pattern = re.compile('|'.join(re.escape(key) for key in replacements.keys()))\n",
    "    return pattern.sub(lambda match: replacements[match.group(0).lower()], string)\n",
    "# Function to clean each entry\n",
    "def clean_data(field):\n",
    "\n",
    "    # Split the field by ','\n",
    "    fields = field.split(',')\n",
    "    # replace special cases:\n",
    "    cleaned_fields = [f.lower() for f in fields] # convert to lower case\n",
    "    cleaned_fields = [replace_substrings(s, mapping_specific_pattern) for s in fields]\n",
    "    # Clean each split value\n",
    "    cleaned_fields = [re.sub(r'\\W+', ' ', f).strip() for f in cleaned_fields] # Remove punctuation\n",
    "    \n",
    "    # mapping specific patterns:\n",
    "    cleaned_fields = [replace_substrings(s, mapping_specific_pattern) for s in cleaned_fields]\n",
    "    # Remove empty fields\n",
    "    cleaned_fields = [f.lower() for f in cleaned_fields if f] # convert to lower case\n",
    "    # Join them back with ','\n",
    "    cleaned_text =  ', '.join(cleaned_fields)\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text)  # Remove multiple spaces\n",
    "    return cleaned_text\n",
    "    \n",
    "cleaned_data['field_of_study'] = cleaned_data['field_of_study'].apply(clean_data)\n",
    "cleaned_data['academic_field'] = cleaned_data['academic_field'].apply(clean_data)\n",
    "cleaned_data['level'] = cleaned_data['level'].apply(clean_data)\n",
    "cleaned_data['level_name'] = cleaned_data['level_name'].apply(clean_data)\n",
    "cleaned_data.replace(\"nan\", pd.NA, inplace=True)\n",
    "# cleaned_data.to_csv('cleaned_data.csv')\n",
    "# data['field_of_study'] = data['field_of_study'].apply(clean_field_of_study)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_data = cleaned_data.dropna()\n",
    "complete_data.to_csv('complete_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate and Standardize Values:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Nearest Neighbors (KNN) imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hkhnhan/Documents/Code/csvprocessing/.venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "knn_data=cleaned_data\n",
    "# Introducing a missing value in 'academic_field' column\n",
    "knn_data.loc[2, 'academic_field'] = None\n",
    "# Encode the 'academic_field' column\n",
    "label_encoder = LabelEncoder()\n",
    "knn_data['academic_field_encoded'] = label_encoder.fit_transform(knn_data['academic_field'].astype(str))\n",
    "knn_data['academic_field_encoded_feature_exatraction'] = label_encoder.fit_transform(knn_data['academic_field'].astype(str))\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "tfidf_vectorizer = TfidfVectorizer(tokenizer=lambda x: x.split(','))\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(knn_data['field_of_study'])\n",
    "\n",
    "# Prepare feature matrix with TF-IDF features\n",
    "feature_matrix = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "feature_matrix['academic_field_encoded_feature_exatraction'] = knn_data['academic_field_encoded_feature_exatraction']\n",
    "\n",
    "# Prepare the feature matrix\n",
    "data_encoded = pd.get_dummies(knn_data['field_of_study'])\n",
    "data_encoded['academic_field_encoded'] = knn_data['academic_field_encoded']\n",
    "\n",
    "\n",
    "data_encoded = pd.concat([data_encoded, feature_matrix], axis=1)\n",
    "# Impute missing values using KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=20) \n",
    "data_imputed = imputer.fit_transform(data_encoded)\n",
    "\n",
    "# Decode the 'academic_field' column back to original labels\n",
    "knn_data['academic_field_imputed'] = label_encoder.inverse_transform(data_imputed[:, -1].round().astype(int))\n",
    "\n",
    "knn_data.drop(['academic_field_encoded','academic_field_encoded_feature_exatraction'], axis=1, inplace=True)\n",
    "knn_data.to_csv('knn_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result, the data from the CSV file still does not contain enough records for some basic ML models to handle the missing data. Manual filling may be necessary."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
